# -*- coding: utf-8 -*-
"""Ethereum Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ih1031dOoxIzwuOmqFCJVov83dVSGJ9O

# Imports
"""

import kagglehub
from kagglehub import KaggleDatasetAdapter
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.impute import SimpleImputer
import pandas as pd
import numpy as np
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as imbPipeline
from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, ConfusionMatrixDisplay, precision_recall_curve

"""# Datset"""

file_path = "transaction_dataset.csv"

df = kagglehub.dataset_load(
  KaggleDatasetAdapter.PANDAS,
  "vagifa/ethereum-frauddetection-dataset",
  file_path,
)

df.head()

df.drop(columns=['Unnamed: 0','Index','Address'],inplace=True)
df.head()

df.info()

df.isna().sum()

for i in df.columns:
  if i.startswith(' '):
    df[i.strip()]=df[i]
    df.drop(i,axis=1,inplace=True)
df.columns

drop_cols=[]
for i in df.select_dtypes(exclude='object').columns:
  #print(i+':',df[i].skew(),df[i].nunique())
  if df[i].skew()==0 and df[i].nunique()==1:
    drop_cols.append(i)
drop_cols

df.drop(drop_cols,axis=1,inplace=True)
df.columns

"""# Precprocessing"""

X=df.drop(columns=['FLAG'])
y=df['FLAG']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

cat_cols=X.select_dtypes(include='object').columns
num_cols=X.select_dtypes(exclude='object').columns

num_pipeline=Pipeline(
    [
        ('imputer',SimpleImputer(strategy='median')),
        ('scaler',StandardScaler())
    ]
)

cat_pipeline=Pipeline(
    [
        ('imputer',SimpleImputer(strategy='most_frequent')),
        ('encoder',OneHotEncoder(handle_unknown='ignore')),
    ]
)

preprocessor=ColumnTransformer([
    ('cat',cat_pipeline,cat_cols),
    ('num',num_pipeline,num_cols),
  ]
)

corr=df.corr(numeric_only=True)
plt.figure(figsize=(50,50))
sns.heatmap(corr, annot=True)

xgb = XGBClassifier(random_state=42)

xgb_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('model', xgb)
])

xgb_pipe.fit(X_train, y_train)
xgb_preds = xgb_pipe.predict(X_test)
xgb_probs = xgb_pipe.predict_proba(X_test)[:,1]

print(classification_report(y_test,xgb_preds))

ConfusionMatrixDisplay(confusion_matrix(y_test,xgb_preds)).plot()

X_train_preprocessed=preprocessor.fit_transform(X_train)
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train_preprocessed, y_train)

print("Before SMOTE:", y_train.value_counts())
print("After SMOTE:", y_train_res.value_counts())

xgb = XGBClassifier(random_state=42)

xgb_smote_pipe = imbPipeline([
    ('preprocessor', preprocessor),
    ('smote',sm),
    ('model', xgb)
])

xgb_smote_pipe.fit(X_train, y_train)
xgb_sm_preds = xgb_smote_pipe.predict(X_test)
xgb_sm_probs = xgb_smote_pipe.predict_proba(X_test)[:,1]

print("Accuracy:", accuracy_score(y_test, xgb_sm_preds))
print("Precision:", precision_score(y_test, xgb_sm_preds))
print("Recall:", recall_score(y_test, xgb_sm_preds))
print("F1 Score:", f1_score(y_test, xgb_sm_preds))

print(classification_report(y_test,xgb_sm_preds))

precisions, recalls, thresholds = precision_recall_curve(y_test, xgb_sm_probs)

f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-6)
best_idx = np.argmax(f1_scores)
best_threshold = thresholds[best_idx]
print("Best threshold for F1:", best_threshold)
print("Max F1 score:", f1_scores[best_idx])

xgb_custom_preds=(xgb_sm_probs >= best_threshold).astype(int)
print(classification_report(y_test, xgb_custom_preds))

ConfusionMatrixDisplay(confusion_matrix(y_test,xgb_custom_preds)).plot()

param_dist = {
    "model__n_estimators": [200, 500, 800],
    "model__max_depth": [3, 5, 7, 10],
    "model__learning_rate": [0.01, 0.05, 0.1],
    "model__subsample": [0.6, 0.8, 1.0],
    "model__colsample_bytree": [0.6, 0.8, 1.0],
    "model__gamma": [0, 1, 5]
}

random_search = RandomizedSearchCV(
    estimator=xgb_smote_pipe,
    param_distributions=param_dist,
    n_iter=20,
    scoring='f1',
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)
best_model = random_search.best_estimator_
print("Best params:", random_search.best_params_)

y_xgb_best_probs = best_model.predict_proba(X_test)[:,1]
y_xgb_best_preds = best_model.predict(X_test)
# ROC AUC
print("Accuracy:", accuracy_score(y_test, y_xgb_best_preds))
print("Precision:", precision_score(y_test, y_xgb_best_preds))
print("Recall:", recall_score(y_test, y_xgb_best_preds))
print("F1 Score:", f1_score(y_test, y_xgb_best_preds))

print(classification_report(y_test,y_xgb_best_preds))

precisions, recalls, thresholds = precision_recall_curve(y_test, xgb_sm_probs)

f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-6)
best_idx = np.argmax(f1_scores)
best_threshold = thresholds[best_idx]
print("Best threshold for F1:", best_threshold)
print("Max F1 score:", f1_scores[best_idx])

xgb_best_custom_preds=(xgb_sm_probs >= best_threshold).astype(int)
print(classification_report(y_test, xgb_best_custom_preds))

ConfusionMatrixDisplay(confusion_matrix(y_test,xgb_best_custom_preds)).plot()

max_i=0
max_j=0
max=0
for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:
  for k in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:
    ensemble_probs =  i* xgb_sm_probs +(1-i)* y_xgb_best_probs
    ensemble_preds = (ensemble_probs >= k).astype(int)
    if f1_score(y_test, ensemble_preds)>max:
      max=f1_score(y_test, ensemble_preds)
      max_i=i
      max_k=k
    #print("F1 Score for weight"+str(i),"and threshold",str(j),str(f1_score(y_test, ensemble_preds)))
print(max,max_i,max_j,max_k)

max_ensemble_probs =  max_i* xgb_sm_probs + (1-max_i) * y_xgb_best_probs
max_ensemble_preds = (max_ensemble_probs >= max_k).astype(int)
print(classification_report(y_test, max_ensemble_preds))

ConfusionMatrixDisplay(confusion_matrix(y_test,max_ensemble_preds)).plot()